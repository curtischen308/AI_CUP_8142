# evaluate.py
import pandas as pd
from sklearn.metrics import f1_score

def evaluate_local_f1(submission_path="outputs/submission.csv", alerts_path="dataset/acct_alert.csv"):
    sub = pd.read_csv(submission_path)
    alerts = pd.read_csv(alerts_path)

    # æ¬„ä½å®¹éŒ¯
    if "acct" not in sub.columns:
        for c in ["acct_id","account","account_id","id"]:
            if c in sub.columns:
                sub = sub.rename(columns={c:"acct"})
                break
    if "acct_id" in alerts.columns:
        alerts = alerts.rename(columns={"acct_id":"acct"})

    alerts["label"] = 1
    df = sub.merge(alerts[["acct","label"]], on="acct", how="left")
    df["label"] = df["label"].fillna(0).astype(int)

    if "pred" not in df.columns:
        raise ValueError("submission æª”ç¼ºå°‘æ¬„ä½ 'pred'ã€‚")
    f1 = f1_score(df["label"], df["pred"])
    print(f"ğŸ“Š æœ¬åœ°é©—è­‰ F1 = {f1:.4f}ï¼ˆåƒ…ä¾›åƒè€ƒï¼Œéå®˜æ–¹ leaderboard åˆ†æ•¸ï¼‰")
    return f1
